#    -*- mode: org -*-


Archived entries from file /home/nilay/Documents/projects/nilaykumar.github.io/content-org/blog/insar-gaza/insar-gaza.org


* interferometric synthetic aperture radar
:PROPERTIES:
:ARCHIVE_TIME: 2024-04-17 Wed 22:38
:ARCHIVE_FILE: ~/Documents/projects/nilaykumar.github.io/content-org/blog/insar-gaza/insar-gaza.org
:ARCHIVE_CATEGORY: insar-gaza
:END:

Unlike visual-spectrum photography, which passively collects incoming light,
synthetic aperture radar (SAR) is an active remote sensing technique. Satellites
equipped with SAR transmit short bursts of microwave-frequency electromagnetic
radiation (radar) focused by an antenna into a beam. The beam hits the surface
of the earth and reflects off, /backscatters/, in various ways, as the image below
shows. INSERT HYP3 SAR IMAGE HERE The precise way in which the radar scatters is
highly dependent on a large number of variables: the incidence angle of the
beam, the difference between the radar wavelength and the size of the objects
being imaged, moisture content of the soil, etc. Intuitively the satellite can
only detect backscatter that bounces back towards itself. A surface that is very
smooth relative to the radar wavelength, for example, will appear very dark in
the resulting image because the beam will bounce almost entirely away from the
satellite. An area with smooth surfaces perpendicular to the smooth ground (e.g.
buildings in an urban environment) on the other hand are often very bright due
to the phenomenon of "double bounce" pictured above. EXAMPLE OF NYC SAR Clearly,
then, SAR imaging produces results quite different than usual photography and
requires some expertise to interpret. Radar does have its benefits though. For
one thing, it's useful even at night. Moreover, weather is no obstacle, which is
quite significant given that about 55% of land tends to be covered by clouds
depending on the season [[cite:&cloud]]. And in fact the way radar interacts with
different materials, water, and vegetation means that it can exploited to
capture information that would otherwise be obscured in photographs. This is why
it's often so useful in ecological applications.

So much for the R in SAR, but what does the descriptor "synthetic aperture"
mean? Actually, before we tackle this question, let's take a look at the
geometry of SAR imaging: INSERT FIGURE 2.1 OF THE HANDBOOK There's a lot going
on here, but I just want to focus on a few points. The first is the acronym
SLAR, Side-Looking Airborne Radar, which is pretty self-explanatory: the radar
beam is sent out of the aircraft or satellite perpendicular to the direction of
travel (the /ground range direction/ is perpendicular to the /along-track
direction/). Side-looking is necessary for imaging because radar measures
distance to a target based on the time of arrival. As the image below
demonstrates, INSERT IMAGE FROM
http://www.csr.utexas.edu/rs/sensors/whatissar/rar.html down-looking radar would
not be able to distinguish between the equidistant points /a/ and /b/ because the
backscattered radar would reach the antenna simultaneously.\footnote{A careful
reader might object that side-looking does not /prove/ that no ambiguities can
arise. Indeed, the resolution of ambiguities is a non-trivial problem and turns
out to pose certain constraints on both hardware and signal processing. For
more details, see section 1.6.1 of [[cite:&sarp]].}

Another thing to notice is that the geometry of SLAR imaging has its own
idiosyncracies. Just as we lose some depth perception when taking a photo from
directly above a subject,
